#!/usr/bin/env python3
"""
ì£¼ì‹ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
yfinanceë¥¼ ì‚¬ìš©í•˜ì—¬ S&P 500 ì¢…ëª©ë“¤ì˜ ê³¼ê±° ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ
"""

import yfinance as yf
import pandas as pd
import os
import time
from datetime import datetime, timedelta
import json

def get_sp500_symbols():
    """S&P 500 ì¢…ëª© ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # Wikipediaì—ì„œ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        tables = pd.read_html(url)
        sp500_table = tables[0]
        symbols = sp500_table['Symbol'].tolist()
        
        # ì¼ë¶€ ì‹¬ë³¼ ì •ë¦¬ (ì ì´ í¬í•¨ëœ ê²½ìš° í•˜ì´í”ˆìœ¼ë¡œ ë³€ê²½)
        cleaned_symbols = []
        for symbol in symbols:
            if '.' in symbol:
                symbol = symbol.replace('.', '-')
            cleaned_symbols.append(symbol)
        
        return cleaned_symbols
    except Exception as e:
        print(f"âŒ S&P 500 ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        # ë°±ì—…ìš© ì£¼ìš” ì¢…ëª©ë“¤
        return ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'JPM', 'JNJ', 'V',
                'WMT', 'PG', 'UNH', 'HD', 'MA', 'DIS', 'PYPL', 'BAC', 'NFLX', 'ADBE',
                'CRM', 'CMCSA', 'XOM', 'VZ', 'KO', 'ABT', 'NKE', 'T', 'TMO', 'COST']

def download_stock_data():
    """S&P 500 ì£¼ì‹ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    
    print("ğŸš€ S&P 500 ì£¼ì‹ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    
    # ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬
    data_dir = "C:/project/Fin-Hub/data/stock-data"
    os.makedirs(data_dir, exist_ok=True)
    
    # S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    print("ğŸ“‹ S&P 500 ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    symbols = get_sp500_symbols()
    print(f"âœ… {len(symbols)}ê°œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì™„ë£Œ")
    
    # ë‚ ì§œ ì„¤ì • (ìµœê·¼ 2ë…„ ë°ì´í„°ë¡œ ì œí•œí•˜ì—¬ ìš©ëŸ‰ ì ˆì•½)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=2*365)  # 2ë…„ ë°ì´í„°
    
    print(f"ğŸ“… ë°ì´í„° ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
    
    successful_downloads = 0
    failed_symbols = []
    download_info = []
    
    # ì²« 100ê°œ ì¢…ëª©ë§Œ ë‹¤ìš´ë¡œë“œ (ìš©ëŸ‰ ì œí•œ)
    symbols_to_download = symbols[:100]
    
    for i, symbol in enumerate(symbols_to_download):
        try:
            print(f"ğŸ“Š ë‹¤ìš´ë¡œë“œ ì¤‘: {symbol} [{i+1}/{len(symbols_to_download)}]")
            
            # yfinanceë¡œ ì£¼ê°€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            stock = yf.Ticker(symbol)
            
            # ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            info = stock.info
            
            # ê³¼ê±° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            hist_data = stock.history(start=start_date, end=end_date, interval="1d")
            
            if not hist_data.empty and len(hist_data) > 100:  # ìµœì†Œ 100ì¼ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•¨
                # ë°ì´í„° ì •ë¦¬
                hist_data.index = hist_data.index.strftime('%Y-%m-%d')
                
                # CSVë¡œ ì €ì¥
                csv_file = os.path.join(data_dir, f"{symbol}.csv")
                hist_data.to_csv(csv_file)
                
                # ì¢…ëª© ì •ë³´ ì €ì¥
                stock_info = {
                    'symbol': symbol,
                    'name': info.get('longName', 'N/A'),
                    'sector': info.get('sector', 'N/A'),
                    'industry': info.get('industry', 'N/A'),
                    'market_cap': info.get('marketCap', 0),
                    'employees': info.get('fullTimeEmployees', 0),
                    'website': info.get('website', 'N/A'),
                    'business_summary': info.get('businessSummary', 'N/A')[:500],  # 500ìë¡œ ì œí•œ
                    'data_points': len(hist_data),
                    'date_range': {
                        'start': hist_data.index[0],
                        'end': hist_data.index[-1]
                    }
                }
                download_info.append(stock_info)
                
                successful_downloads += 1
                print(f"âœ… {symbol} ë°ì´í„° ì €ì¥ ì™„ë£Œ ({len(hist_data)}ì¼ ë°ì´í„°)")
                
            else:
                print(f"âš ï¸ {symbol} ë°ì´í„° ë¶€ì¡± (ê±´ë„ˆëœ€)")
                failed_symbols.append(symbol)
            
            # API í˜¸ì¶œ ì œí•œ ì¤€ìˆ˜
            time.sleep(0.1)
            
        except Exception as e:
            print(f"âŒ {symbol} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            failed_symbols.append(symbol)
            time.sleep(0.5)
    
    # ì¢…ëª© ì •ë³´ ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        'download_date': datetime.now().isoformat(),
        'data_source': 'Yahoo Finance (yfinance)',
        'total_symbols_requested': len(symbols_to_download),
        'successful_downloads': successful_downloads,
        'failed_downloads': len(failed_symbols),
        'failed_symbols': failed_symbols,
        'data_period_days': (end_date - start_date).days,
        'date_range': {
            'start': start_date.strftime('%Y-%m-%d'),
            'end': end_date.strftime('%Y-%m-%d')
        },
        'stocks_info': download_info
    }
    
    metadata_file = os.path.join(data_dir, "_metadata.json")
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    # ê²°ê³¼ ìš”ì•½
    print("\nğŸ“ˆ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ìš”ì•½:")
    print(f"âœ… ì„±ê³µ: {successful_downloads}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {len(failed_symbols)}ê°œ")
    print(f"ğŸ’¾ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_file}")
    
    if failed_symbols:
        print(f"ì‹¤íŒ¨ ëª©ë¡: {', '.join(failed_symbols[:10])}{'...' if len(failed_symbols) > 10 else ''}")
    
    print("ğŸ‰ ì£¼ì‹ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

if __name__ == "__main__":
    download_stock_data()